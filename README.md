# Oneshot Motion Mimic main model
---
This repo is based on the official implementation of the papers:
  
Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis  
Ye Yuan, Kris Kitani  
**NeurIPS 2020**  
[[website](https://www.ye-yuan.com/rfc)] [[paper](https://arxiv.org/pdf/2006.07364.pdf)] [[video](https://youtu.be/XuzH1u78o1Y)]

MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies 
Xuebin Peng et al.
**NeurIPS 2019**  
[[website](https://xbpeng.github.io/projects/MCP/index.html)] [[paper](https://xbpeng.github.io/projects/MCP/2019_MCP.pdf)] [[video](https://www.youtube.com/watch?v=ChxSx8-sX_c&t=1s)]

# Installation 
### Dataset and Pretrained Models
* The CMU mocap data we use is already included in the [data/cmu_mocap](data/cmu_mocap) folder. The pretrained models are in [results/motion_im](results/motion_im) where each subfolder (e.g., [0506](results/motion_im/0506)) corresponds to a training config file (e.g., [0506.yml](motion_imitation/cfg/0506.yml)) in [motion_imitation/cfg](motion_imitation/cfg).
* We have provided the following configs (label): 
02 (walking, turning).
### Environment
* **Tested OS:** MacOS, Linux
* Python >= 3.6
### How to install
1. Install the dependencies:
    ```
    pip install -r requirements.txt
    ```
2. Install MuJoCo following the steps [here](https://github.com/openai/mujoco-py#install-mujoco). Note that [mujoco-py](https://github.com/openai/mujoco-py) (MuJoCo's python binding) is already installed in step 1. This step is to install the actual MuJoCo library.  
   **Note: [MuJoCo](https://mujoco.org/) is now free thanks to DeepMind!** ðŸŽ‰ðŸŽ‰ðŸŽ‰
3. Set the following environment variable to improve multi-threaded sampling performance:    
    ```
    export OMP_NUM_THREADS=1
    ```

# Quick Demo
### Visualize of our final result
```
python motion_imitation/vis_motion_parser_no_grad.py --cfg 02 --iter 2000 --exp_name track_200_mul -mp_name track_200_morerandom --steps 200 --expert_id 3
```

**Keyboard shortcuts** for the GUI:  
| Key           | Functionality          | Key           | Functionality          |
| ------------- | ---------------------- | ------------- | ---------------------- |
| space         | pause/resume animation | w/e           | go to first/last frame |
| left/right    | previous/next frame    | d/f           | slow down/speed up     |
| g             | toggle loop            | s             | toggle reverse         |

# Training

### Train MoE policy

To train an MoE policy via deep mimic, just run:
```
python motion_imitation/motion_im_mt.py --cfg 022 --num_threads <max_num_CPU_threads_you_have> --exp_name <name your experiment> --policy <cond/multiplicative/additive>
```
This will save models and logs into [results/motion_im/022](results/motion_im/022).

